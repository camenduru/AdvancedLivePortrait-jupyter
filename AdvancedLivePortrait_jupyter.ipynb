{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/camenduru/AdvancedLivePortrait-jupyter/blob/main/AdvancedLivePortrait_jupyter.ipynb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VjYy0F2gZIPR"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone -b totoro5 https://github.com/camenduru/ComfyUI /content/TotoroUI\n",
        "!git clone -b totoro5 https://github.com/camenduru/ComfyUI-AdvancedLivePortrait /content/TotoroUI/custom_nodes/TotoroUI-AdvancedLivePortrait\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "!pip install torchsde dill ultralytics\n",
        "!mkdir -p /content/TotoroUI/output/exp_data\n",
        "\n",
        "!apt -y install -qq aria2\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://huggingface.co/camenduru/LivePortrait_InsightFace/resolve/main/liveportrait/human/appearance_feature_extractor.safetensors -d /content/TotoroUI/models/liveportrait -o appearance_feature_extractor.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://huggingface.co/camenduru/LivePortrait_InsightFace/resolve/main/liveportrait/human/landmark.onnx -d /content/TotoroUI/models/liveportrait -o landmark.onnx\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://huggingface.co/camenduru/LivePortrait_InsightFace/resolve/main/liveportrait/human/landmark_model.pth -d /content/TotoroUI/models/liveportrait -o landmark_model.pth\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://huggingface.co/camenduru/LivePortrait_InsightFace/resolve/main/liveportrait/human/motion_extractor.safetensors -d /content/TotoroUI/models/liveportrait -o motion_extractor.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://huggingface.co/camenduru/LivePortrait_InsightFace/resolve/main/liveportrait/human/spade_generator.safetensors -d /content/TotoroUI/models/liveportrait -o spade_generator.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://huggingface.co/camenduru/LivePortrait_InsightFace/resolve/main/liveportrait/human/stitching_retargeting_module.safetensors -d /content/TotoroUI/models/liveportrait -o stitching_retargeting_module.safetensors\n",
        "!aria2c --console-log-level=error -c -x 16 -s 16 -k 1M  https://huggingface.co/camenduru/LivePortrait_InsightFace/resolve/main/liveportrait/human/warping_module.safetensors -d /content/TotoroUI/models/liveportrait -o warping_module.safetensors\n",
        "\n",
        "%cd /content/TotoroUI\n",
        "\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import nodes\n",
        "from nodes import NODE_CLASS_MAPPINGS\n",
        "from nodes import load_custom_node\n",
        "\n",
        "load_custom_node(\"/content/TotoroUI/custom_nodes/TotoroUI-AdvancedLivePortrait\")\n",
        "LoadImage = NODE_CLASS_MAPPINGS[\"LoadImage\"]()\n",
        "ExpressionEditor = NODE_CLASS_MAPPINGS[\"ExpressionEditor\"]()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "src_image = LoadImage.load_image('/content/test.png')[0]\n",
        "\n",
        "rotate_pitch=0.0\n",
        "rotate_yaw=0.0\n",
        "rotate_roll=0.0\n",
        "blink=0.0\n",
        "eyebrow=0.0\n",
        "wink=0.0\n",
        "pupil_x=0.0\n",
        "pupil_y=0.0\n",
        "aaa=0.0\n",
        "eee=0.0\n",
        "woo=0.0\n",
        "smile=1.30\n",
        "src_ratio=0.0\n",
        "sample_ratio=0.0\n",
        "sample_parts=\"OnlyExpression\"\n",
        "crop_factor=1.7\n",
        "sample_image=None\n",
        "motion_link=None\n",
        "add_exp=None\n",
        "\n",
        "output_image = ExpressionEditor.run(rotate_pitch, rotate_yaw, rotate_roll, blink, eyebrow, wink, pupil_x, pupil_y, aaa, eee, woo, smile, src_ratio, sample_ratio, sample_parts, crop_factor, src_image=src_image, sample_image=None, motion_link=None, add_exp=None)\n",
        "Image.fromarray(np.array(output_image['result'][0]*255, dtype=np.uint8)[0])"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
